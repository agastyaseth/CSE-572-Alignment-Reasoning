# Impact of Simplified Alignment on LLM Reasoning Performance

This repository contains the code and resources for our **CSE572 Data Mining Project**, titled *"Impact of Simplified Alignment on LLM Reasoning Performance."*

## Project Overview

The project explores how aligning large language models (LLMs) to generate simplified, ELI5-style responses impacts their reasoning capabilities on complex benchmarks such as **MMLU** and **GSM8K**. We aim to evaluate the trade-offs between clarity and reasoning depth through alignment using the **Direct Preference Optimization (DPO)** framework.

## Current Status

- **Completed:** 
  - Data preprocessing for ELI5, MMLU, and GSM8K datasets.
  - Initial setup of the DPO framework for ELI5 alignment.

- **In Progress:** 
  - Fine-tuning and evaluation of LLMs for reasoning performance.

## Datasets

- **Alignment Dataset:** ELI5 (simplified question-answer pairs)
- **Evaluation Datasets:** MMLU (multi-subject benchmark) and GSM8K (math word problems)

## License

This project is part of the coursework for CSE572 and is for academic purposes only.
